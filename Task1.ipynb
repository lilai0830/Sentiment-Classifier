{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb9995d",
   "metadata": {},
   "source": [
    "Task 1. Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4284abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from argparse import Namespace\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e708bdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rating",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "c3f77817-a074-4885-86cd-bb9b45b68244",
       "rows": [
        [
         "0",
         "negative",
         "I will never again visit the VCA Fox Chapel, and I caution against you doing so as well.  I took my extremely ill, very old cat there two days ago and we were dismissed out of hand.  No tests were run by Dr. Resek and we were sent out the door with a diagnosis of general food poisoning.  This morning, my cat's condition was visibly worse - she has not eaten in four days - and I called them for counsel.  After 2 five-minute long periods of holding, I was again dismissed by the office staff and told that the recommendation of the doctor was to continue feeding her bland food.  MY CAT IS NOT EATING.  \\n\\nThey were also kind enough to offer me the option of coming in at an elevated \\\"emergency rate.\\\"  Thanks, but no.  I instead took her to another provider who was thoughtful, thorough and who diagnosed her with acute kidney failure.\\n\\nMy question to the folks at VCA Fox Chapel is this: if you do not care about sick animals, why are you in the veterinary profession? I will be posing this question to them directly.\\n\\nIn the meantime, I advise you, Reader, if you do care about your animal to NOT TAKE IT TO VCA.  They are, in my opinion, directly responsible for the unnecessarily prolonged suffering of my dearest friend - an elderly sweetheart who at this stage in her life deserves far, far better.\\n\\n(And I would like to point out that I granted them one star because Yelp made me.)",
         "train"
        ],
        [
         "1",
         "negative",
         "Food is mediocre service is lousy. I'm sitting here right now and have been out of water and done eating for 20 min...",
         "train"
        ],
        [
         "2",
         "negative",
         "Who deleted my review of Sunnyledge?\\n\\nBack in April, I met a girl for drinks at the Sunnyledge.  We had both heard good things about the place and that they had a great martini menu.  When we arrived there, however it was a different story.  We were met at the door by the hostess (I presume) who did not take our arrival kindly and seemed annoyed that we were there.\\n\\nWe shrugged it off and went to the bar.  The bartender was something else and it seemed as if he was on a variety of drugs. He acted as if he was on the last quaaludes in his posession and moved with a subtle grace most often reserved for Miss Universe pageant constestants.  And that's saying something.\\n\\nThe bartender would disappear for long periods of time, during which we would hear odd sounds coming from the kitchen.  Mostly the sounds of silverware banging around.  It was as if the hostess and bartender were throwing cutlery at each other in attempts to get us to think just what the hell was going on.  We were there for about 2 hours  and during that time saw the bartender a total of 4 times.  Most of the time he was hiding out in the kitchen.  \\n\\nEven when it came time to get our check, it took about 15 minutes for him to return with my card.\\n\\nTerrible service that night from an otherwise reputable place.  I have no plans on returning.\\n\\nI hope this isn't deleted again, and if it is, I will make sure it's well known and will take printed copies of this and put them up around Sunnyledge and use every contact I have to get this printed in the Post Gazette and City Paper.  I have the means, I have the will.",
         "train"
        ],
        [
         "3",
         "negative",
         "I went here for a business lunch the other day, and as a petite woman, even I was shocked at how small the portions were.  I typically need a to go box whenever I go out to eat, but here I finished my entire meal (trout and potatoes) and was still hungry.  We all ended up ordering dessert and laughed when we saw it.  The $7 cheesecake could fit on a tablespoon!  The service was pretty good in the beginning, but as the place filled up our server seemed to disappear.  He never returned to refill our glasses or bring the missing ice cream that was supposed to go with my dessert!  While the restaurant interior is lovely and the location is great for all those that work in uptown, the price you pay for the small amount of food makes it not worth it.",
         "train"
        ],
        [
         "4",
         "negative",
         "This business closed July 31st 2014!!",
         "train"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>I will never again visit the VCA Fox Chapel, a...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Food is mediocre service is lousy. I'm sitting...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Who deleted my review of Sunnyledge?\\n\\nBack i...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>I went here for a business lunch the other day...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This business closed July 31st 2014!!</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating                                             review  split\n",
       "0  negative  I will never again visit the VCA Fox Chapel, a...  train\n",
       "1  negative  Food is mediocre service is lousy. I'm sitting...  train\n",
       "2  negative  Who deleted my review of Sunnyledge?\\n\\nBack i...  train\n",
       "3  negative  I went here for a business lunch the other day...  train\n",
       "4  negative              This business closed July 31st 2014!!  train"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reviews_with_splits_lite.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f40d12",
   "metadata": {},
   "source": [
    "EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4db5305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic information：\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7280 entries, 0 to 7279\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   rating            7280 non-null   object\n",
      " 1   review            7280 non-null   object\n",
      " 2   split             7280 non-null   object\n",
      " 3   processed_review  7280 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 227.6+ KB\n",
      "None\n",
      "\n",
      "DIstribution of sentiment labels：\n",
      "rating\n",
      "negative    3640\n",
      "positive    3640\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EDA - Exploratory Data Analysis\n",
    "\n",
    "print(\"Basic information：\")\n",
    "print(df.info())\n",
    "print(\"\\nDIstribution of sentiment labels：\")\n",
    "print(df['rating'].value_counts())\n",
    "\n",
    "# Visualizing the distribution of sentiment labels\n",
    "sns.countplot(x='rating', data=df)\n",
    "plt.title(\"Yelp Review Sentiment Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc02bc",
   "metadata": {},
   "source": [
    "Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd6875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lilai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lilai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lilai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocess - Defining the text preprocessing function\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Replacing the original labels with binary labels (0 for negative, 1 for positive)\n",
    "df['rating'] = df['rating'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Decapitalization and removing special characters\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # spliting words into list\n",
    "    words = text.split()\n",
    "    # stop words removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # returning into string\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['processed_review'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating the data into train, validation and test sets\n",
    "\n",
    "train_text = df[df['split'] == 'train']['processed_review'].values\n",
    "train_labels = df[df['split'] == 'train']['rating'].values\n",
    "val_text = df[df['split'] == 'val']['processed_review'].values\n",
    "val_labels = df[df['split'] == 'val']['rating'].values\n",
    "test_text = df[df['split'] == 'test']['processed_review'].values\n",
    "test_labels = df[df['split'] == 'test']['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a175b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000) # limiting to top 5000 features, preventing overfitting\n",
    "X_train = vectorizer.fit_transform(train_text).toarray()\n",
    "X_val = vectorizer.transform(val_text).toarray()\n",
    "X_test = vectorizer.transform(test_text).toarray()\n",
    "\n",
    "# Converting to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(val_labels, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(test_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba15aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a custom dataset for reviews\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6349bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(TextDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TextDataset(X_val_tensor, y_val_tensor), batch_size=batch_size)\n",
    "test_loader = DataLoader(TextDataset(X_test_tensor, y_test_tensor), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85b202",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aff1b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewClassifier(nn.Module):\n",
    "    \"\"\" a simple perceptron based classifier \"\"\"\n",
    "    def __init__(self, num_features, hidden_dim):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_features (int): the size of the input feature vector\n",
    "            hidden_dim   (int): the size of hidden dimension\n",
    "        \"\"\"\n",
    "        super(ReviewClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=num_features, out_features=hidden_dim)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_dim, out_features=1)\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        \"\"\"The forward pass of the classifier    \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be [batch, num_features]\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be [batch]\n",
    "        \"\"\"\n",
    "        intermediate = self.fc1(x_in)            # [batch, num_features] -> [batch, hidden_dim]\n",
    "        intermediate = F.relu(intermediate)      # [batch, hidden_dim]\n",
    "        y_out = self.fc2(intermediate)           # [batch, hidden_dim] -> [batch, out_features]\n",
    "               \n",
    "        return torch.sigmoid(y_out).squeeze()    # [batch, 1] -> [batch] (e.g., [0.3, 0.1, 0.7, 0.8, ..., 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f41fe5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "\n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # If loss worsened\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t  # update 'early_stopping_best_val'\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    y_target = y_target.cpu()\n",
    "    y_pred_indices = (y_pred>0.5).cpu().long()\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()  # item() to get a Python number from a tensor containing a single value\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fddb0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34892097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\tmodel_storage/ch3/yelp/model.pth\n",
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and Path information\n",
    "    frequency_cutoff=25,\n",
    "    model_state_file='model.pth',\n",
    "    review_csv='reviews_with_splits_lite.csv',\n",
    "    save_dir='model_storage/',\n",
    "    # No Model hyper parameters\n",
    "    hidden_dim=20,\n",
    "    # Training hyper parameters\n",
    "    batch_size=128,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=100,\n",
    "    seed=1337,\n",
    "    # Runtime options\n",
    "    catch_keyboard_interrupt=True,\n",
    "    cuda=True,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    "    reload_from_files=False,\n",
    ")\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs ; creat dirs if they don't exist\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4aac6e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset and creating vectorizer\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'ReviewDataset' has no attribute 'load_dataset_and_make_vectorizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading dataset and creating vectorizer\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# create dataset and vectorizer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m dataset = \u001b[43mReviewDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_dataset_and_make_vectorizer\u001b[49m(args.review_csv, args.frequency_cutoff) \n\u001b[32m      5\u001b[39m vectorizer = dataset.get_vectorizer()\n\u001b[32m      7\u001b[39m classifier = ReviewClassifier(num_features=\u001b[38;5;28mlen\u001b[39m(vectorizer.review_vocab), hidden_dim=args.hidden_dim)\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'ReviewDataset' has no attribute 'load_dataset_and_make_vectorizer'"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset and creating vectorizer\")\n",
    "# create dataset and vectorizer\n",
    "dataset = ReviewDataset.load_dataset_and_make_vectorizer(args.review_csv, args.frequency_cutoff) \n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "classifier = ReviewClassifier(num_features=len(vectorizer.review_vocab), hidden_dim=args.hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279f705",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(vectorizer.review_vocab), str(vectorizer.rating_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eced9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min', factor=0.1,\n",
    "                                                 patience=10) # Reduce learning rate when a metric has stopped improving.\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)  # progress bar\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------\n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'].float())  # [batch, num_features] -> [batch]\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            \n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, \n",
    "                                  acc=running_acc, \n",
    "                                  epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "        \n",
    "        train_state['train_loss'].append(running_loss)  # train_loss for each epoch\n",
    "        train_state['train_acc'].append(running_acc)    # train_acc for each epoch\n",
    "        \n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "          for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "            # compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            \n",
    "            val_bar.set_postfix(loss=running_loss, \n",
    "                                acc=running_acc, \n",
    "                                epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)  # val_loss for each epoch\n",
    "        train_state['val_acc'].append(running_acc)    # val_acc for each epoch\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier,\n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])  # adjust learning rate\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "\n",
    "        train_bar.reset()   # reset number of finished iterations\n",
    "        val_bar.reset()\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b378d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "acc = train_state['train_acc']\n",
    "val_acc = train_state['val_acc']\n",
    "loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "epochs = list(range(1, len(acc) + 1))\n",
    "\n",
    "# Create interactive line chart\n",
    "fig = go.Figure()\n",
    "\n",
    "for y, name, color, mode in [(loss, 'Training Loss', 'blue', 'lines+markers'),\n",
    "                             (val_loss, 'Validation Loss', 'royalblue', 'lines')]:\n",
    "    fig.add_trace(go.Scatter(x=epochs, y=y, mode=mode, name=name, line=dict(color=color)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Training and Validation Loss',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='Loss',\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec9264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive line chart for accuracy\n",
    "fig = go.Figure()\n",
    "\n",
    "for y, name, color, mode in [(acc, 'Training Accuracy', 'blue', 'lines+markers'),\n",
    "                             (val_acc, 'Validation Accuracy', 'royalblue', 'lines')]:\n",
    "    fig.add_trace(go.Scatter(x=epochs, y=y, mode=mode, name=name, line=dict(color=color)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Training and Validation Accuracy',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='Accuracy',\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6f696",
   "metadata": {},
   "source": [
    "豆包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2947d5aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\__init__.py:73\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[32m     70\u001b[39m     __check_build,\n\u001b[32m     71\u001b[39m     _distributor_init,\n\u001b[32m     72\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     76\u001b[39m _submodules = [\n\u001b[32m     77\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcalibration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     78\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompose\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    115\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_missing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_scalar_nan\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\__init__.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_chunking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_indexing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     _safe_indexing,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     18\u001b[39m     resample,\n\u001b[32m     19\u001b[39m     shuffle,\n\u001b[32m     20\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_chunking.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[32m     15\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Integral, Real\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\__init__.py:305\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_importlib\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_csr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_csc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\_csr.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_matrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _spbase, sparray\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sparsetools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[32m     12\u001b[39m                            get_csr_submatrix, csr_sample_values)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m upcast\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compressed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _cs_matrix\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class SentimentMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1=256, hidden_dim2=128, output_dim=5, dropout_rate=0.3):\n",
    "        super(SentimentMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.BatchNorm1d(hidden_dim1),  # 批归一化\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),     # Dropout防止过拟合\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.BatchNorm1d(hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim2, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 初始化模型\n",
    "input_dim = X_train.shape[1]  # TF-IDF特征维度\n",
    "model = SentimentMLP(input_dim)\n",
    "\n",
    "# ====================== 3. 训练与优化（优化点：调整学习率+选择优化器） ======================\n",
    "# 损失函数+优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 优化点：学习率0.001（可尝试0.0005/0.002）\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)  # 学习率衰减\n",
    "\n",
    "# 训练函数\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20):\n",
    "    best_val_acc = 0.0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * batch_X.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item() * batch_X.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_preds.extend(preds.numpy())\n",
    "                val_true.extend(batch_y.numpy())\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        val_acc = accuracy_score(val_true, val_preds)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # 学习率衰减\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # 保存最优模型\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), './models/sentiment_model.pth')\n",
    "        \n",
    "        # 打印日志\n",
    "        print(f'Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
    "    \n",
    "    return train_losses, val_losses, val_accs, best_val_acc\n",
    "\n",
    "# 开始训练\n",
    "train_losses, val_losses, val_accs, best_val_acc = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20)\n",
    "\n",
    "# ====================== 4. 测试最优模型 ======================\n",
    "# 加载最优模型\n",
    "best_model = SentimentMLP(input_dim)\n",
    "best_model.load_state_dict(torch.load('./models/sentiment_model.pth'))\n",
    "best_model.eval()\n",
    "\n",
    "# 测试集评估\n",
    "test_preds = []\n",
    "test_true = []\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = best_model(batch_X)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_preds.extend(preds.numpy())\n",
    "        test_true.extend(batch_y.numpy())\n",
    "test_acc = accuracy_score(test_true, test_preds)\n",
    "test_loss = criterion(best_model(X_test_tensor), y_test_tensor).item()\n",
    "\n",
    "print(f'最优模型测试准确率: {test_acc:.4f} | 测试损失: {test_loss:.4f}')\n",
    "\n",
    "# ====================== 5. 超参数调优（对比5组模型） ======================\n",
    "# 示例：调整不同超参数组合，记录结果\n",
    "hyper_params = [\n",
    "    {'hidden_dim1': 128, 'hidden_dim2': 64, 'lr': 0.001, 'dropout': 0.2},\n",
    "    {'hidden_dim1': 256, 'hidden_dim2': 128, 'lr': 0.001, 'dropout': 0.3},\n",
    "    {'hidden_dim1': 512, 'hidden_dim2': 256, 'lr': 0.001, 'dropout': 0.3},\n",
    "    {'hidden_dim1': 256, 'hidden_dim2': 128, 'lr': 0.0005, 'dropout': 0.3},\n",
    "    {'hidden_dim1': 256, 'hidden_dim2': 128, 'lr': 0.001, 'dropout': 0.4},\n",
    "]\n",
    "\n",
    "# 记录5组模型的结果（简化版，实际需完整训练）\n",
    "results = []\n",
    "for i, params in enumerate(hyper_params):\n",
    "    print(f'训练第{i+1}组模型: {params}')\n",
    "    temp_model = SentimentMLP(input_dim, params['hidden_dim1'], params['hidden_dim2'], dropout_rate=params['dropout'])\n",
    "    temp_optimizer = optim.Adam(temp_model.parameters(), lr=params['lr'])\n",
    "    _, _, _, temp_best_val_acc = train_model(temp_model, train_loader, val_loader, criterion, temp_optimizer, epochs=15)\n",
    "    \n",
    "    # 测试集评估\n",
    "    temp_model.eval()\n",
    "    temp_test_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            outputs = temp_model(batch_X)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            temp_test_preds.extend(preds.numpy())\n",
    "    temp_test_acc = accuracy_score(test_true, temp_test_preds)\n",
    "    \n",
    "    results.append({\n",
    "        'params': params,\n",
    "        'val_acc': temp_best_val_acc,\n",
    "        'test_acc': temp_test_acc,\n",
    "        'test_loss': criterion(temp_model(X_test_tensor), y_test_tensor).item()\n",
    "    })\n",
    "\n",
    "# 打印5组模型结果（用于报告）\n",
    "for i, res in enumerate(results):\n",
    "    print(f'第{i+1}组模型 | 验证准确率: {res[\"val_acc\"]:.4f} | 测试准确率: {res[\"test_acc\"]:.4f} | 测试损失: {res[\"test_loss\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc38c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df280050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8145dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45ee9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
